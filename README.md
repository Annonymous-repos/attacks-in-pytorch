# attacks-in-pytorch
Reproduces BPDA attack in pytorch


Pytorch implementation of two attack methods in paper [Obfuscated Gradients Give a False Sense of Security:Circumventing Defenses to Adversarial Examples](https://arxiv.org/abs/1802.00420)

## Environment

- python=3.6.8  
- pytorch=1.1.0   
- numpy=1.13.3
- [advertorch](https://github.com/BorealisAI/advertorch)

## Acknowledgement
This repository utilizes the source codes of  "Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples"

- [obfuscated-gradients](https://github.com/anishathalye/obfuscated-gradients)
   
